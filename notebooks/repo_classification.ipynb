{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Categorising repositories\n",
    "\n",
    "This notebook is an attempt to categorise repositories and build classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oss4energy.src.parsers.opensustain_tech import (\n",
    "    fetch_categorised_projects_from_opensustain_webpage,\n",
    ")\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "categorised_repos = fetch_categorised_projects_from_opensustain_webpage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(list(categorised_repos.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint({k: list(v.keys()) for k, v in categorised_repos.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Working out manual categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making manual categories to start with\n",
    "ENERGY = [\"Energy Storage\", \"Energy Systems\", \"Renewable Energy\"]\n",
    "EARTH_SCIENCE = [\n",
    "    \"Atmosphere\",\n",
    "    \"Hydrosphere\",\n",
    "    \"Cryosphere\",\n",
    "    {\"Climate Change\": [\"Earth and Climate Modeling\"]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oss4energy.src.parsers import identify_parsing_targets\n",
    "\n",
    "\n",
    "def f_aggregate_to_list(\n",
    "    repo_dict, path_labels: list[str | dict[str, list[str]]] | None = None\n",
    "):\n",
    "    # If not provided, the labels are set so that the whole data is imported\n",
    "    if path_labels is None:\n",
    "        path_labels = list(repo_dict.keys())\n",
    "\n",
    "    out = list()\n",
    "    for i in path_labels:\n",
    "        sub_categories = []\n",
    "        if isinstance(i, str):\n",
    "            i_out = i\n",
    "            sub_categories = list(repo_dict.get(i).keys())\n",
    "        elif isinstance(i, dict):\n",
    "            i_out = list(i.keys())[0]\n",
    "            sub_categories = list(i.values())[0]\n",
    "\n",
    "        for c in sub_categories:\n",
    "            out += repo_dict.get(i_out).get(c)\n",
    "\n",
    "    return identify_parsing_targets(out).as_url_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"\"\"Testing:\n",
    "    - ENERGY: {len(f_aggregate_to_list(categorised_repos, ENERGY))}\n",
    "    - EARTH_SCIENCE: {len(f_aggregate_to_list(categorised_repos, EARTH_SCIENCE))}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Building up a series of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oss4energy.scripts.listing_search import FILE_OUTPUT_LISTING_FEATHER, SearchResults\n",
    "import pandas as pd\n",
    "\n",
    "res = SearchResults(\"../\" + FILE_OUTPUT_LISTING_FEATHER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs = res.documents.set_index(\"id\")\n",
    "print(len(df_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Adding categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_listed = df_docs[\"url\"].to_list()\n",
    "all_opensustain_repos = f_aggregate_to_list(categorised_repos)\n",
    "energy_repos = f_aggregate_to_list(categorised_repos, ENERGY)\n",
    "earth_science_repos = f_aggregate_to_list(categorised_repos, EARTH_SCIENCE)\n",
    "\n",
    "\n",
    "def _f_in_list(x) -> bool:\n",
    "    return x in repos_listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels\n",
    "category_col = \"category\"\n",
    "df_docs[\"idx\"] = df_docs[\"url\"]\n",
    "df_docs.set_index(\"idx\", inplace=True)\n",
    "df_docs[category_col] = \"?\"\n",
    "df_docs.loc[list(filter(_f_in_list, all_opensustain_repos)), category_col] = \"OTHER\"\n",
    "df_docs.loc[list(filter(_f_in_list, energy_repos)), category_col] = \"ENERGY\"\n",
    "df_docs.loc[list(filter(_f_in_list, earth_science_repos)), category_col] = (\n",
    "    \"EARTH_SCIENCE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Training classifier\n",
    "\n",
    "Tips from https://scikit-learn.org/1.5/auto_examples/text/plot_document_classification_20newsgroups.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_selected = [\"OTHER\", \"ENERGY\", \"EARTH_SCIENCE\"]\n",
    "\n",
    "df4training = df_docs[df_docs[category_col].apply(lambda x: x in x_selected)].copy()\n",
    "df4training = df4training[df4training[\"description\"].apply(lambda x: x is not None)]\n",
    "df4training[[category_col, \"name\"]].groupby(category_col).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, training on full dataset and not cleaning up words (VERY DIRTY)\n",
    "vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True, max_df=0.5, min_df=5, stop_words=\"english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_full = vectorizer.fit_transform(df4training[\"description\"])\n",
    "# x_full = vectorizer.fit_transform(df4training[\"readme\"])\n",
    "y_full = df4training[category_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_full, y_full, test_size=0.4, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Trying out ridge classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "clf = RidgeClassifier(tol=1e-2, solver=\"sparse_cg\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_on_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predicted_on_test, ax=ax)\n",
    "_ = ax.set_title(\n",
    "    f\"Confusion Matrix for {clf.__class__.__name__}\\non the test documents\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COpy/pasted from https://scikit-learn.org/1.5/auto_examples/text/plot_document_classification_20newsgroups.html\n",
    "\n",
    "categories = x_selected\n",
    "target_names = x_selected\n",
    "\n",
    "\n",
    "def plot_feature_effects():\n",
    "    # learned coefficients weighted by frequency of appearance\n",
    "    average_feature_effects = clf.coef_ * np.asarray(X_train.mean(axis=0)).ravel()\n",
    "\n",
    "    for i, label in enumerate(target_names):\n",
    "        top5 = np.argsort(average_feature_effects[i])[-5:][::-1]\n",
    "        if i == 0:\n",
    "            top = pd.DataFrame(feature_names[top5], columns=[label])\n",
    "            top_indices = top5\n",
    "        else:\n",
    "            top[label] = feature_names[top5]\n",
    "            top_indices = np.concatenate((top_indices, top5), axis=None)\n",
    "    top_indices = np.unique(top_indices)\n",
    "    predictive_words = feature_names[top_indices]\n",
    "\n",
    "    # plot feature effects\n",
    "    bar_size = 0.25\n",
    "    padding = 0.75\n",
    "    y_locs = np.arange(len(top_indices)) * (4 * bar_size + padding)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    for i, label in enumerate(target_names):\n",
    "        ax.barh(\n",
    "            y_locs + (i - 2) * bar_size,\n",
    "            average_feature_effects[i, top_indices],\n",
    "            height=bar_size,\n",
    "            label=label,\n",
    "        )\n",
    "    ax.set(\n",
    "        yticks=y_locs,\n",
    "        yticklabels=predictive_words,\n",
    "        ylim=[\n",
    "            0 - 4 * bar_size,\n",
    "            len(top_indices) * (4 * bar_size + padding) - 4 * bar_size,\n",
    "        ],\n",
    "    )\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    print(\"top 5 keywords per class:\")\n",
    "    print(top)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "_ = plot_feature_effects().set_title(\"Average feature effect on the original data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "For future work:\n",
    "- [ ] Augment the original dataset with the categorical columns, where available\n",
    "- [ ] Explore the performance of different classifiers (bag of words is pretty naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
